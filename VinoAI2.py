import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from mlxtend.feature_selection import SequentialFeatureSelector as SFS

# Configurar estilo de grÃ¡ficos
sns.set(style="whitegrid")

# Cargar los datos
file_path = r"C:\Users\jonat\Downloads\visual\A1.4 Vino Tinto.csv"
df = pd.read_csv(file_path)

# Mostrar dimensiones y primeras filas del DataFrame
print("### **Reporte de Resultados: Actividad A1.4 - SelecciÃ³n de CaracterÃ­sticas**")
print("\n#### **1. ImportaciÃ³n de los Datos**")
print(f"- **Dimensiones del DataFrame**: {df.shape}")
print("- **Primeras 5 filas de datos:**")
print(df.head())

# Separar las variables predictoras (X) y la variable objetivo (y)
X = df.drop(columns=['calidad'])  # Variable objetivo: calidad
y = df['calidad']

# DivisiÃ³n de los datos en entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\n#### **2. SeparaciÃ³n de Datos en Entrenamiento y Prueba**")
print(f"- **Entrenamiento (X_train)**: {X_train.shape}")
print(f"- **Prueba (X_test)**: {X_test.shape}")

# Histograma de calidad del vino
plt.figure(figsize=(8, 5))
sns.histplot(y, bins=10, kde=True, color="blue")
plt.title("DistribuciÃ³n de Calidad del Vino")
plt.xlabel("Calidad")
plt.ylabel("Frecuencia")
plt.savefig("histograma_calidad.png")
plt.show()

# ConfiguraciÃ³n del modelo de regresiÃ³n
model = LinearRegression()

# ======= SELECCIÃ“N HACIA ADELANTE =======
sfs_forward = SFS(model, k_features=(2, 8), forward=True, floating=False, scoring='r2', cv=10)
sfs_forward.fit(X_train, y_train)
selected_features_forward = list(sfs_forward.k_feature_names_)

print("\n#### **3. SelecciÃ³n Hacia Adelante**")
print(f"- **CaracterÃ­sticas seleccionadas**: {selected_features_forward}")

# Entrenar el modelo con selecciÃ³n hacia adelante
X_train_forward = X_train[selected_features_forward]
X_test_forward = X_test[selected_features_forward]
model.fit(X_train_forward, y_train)
y_pred_forward = model.predict(X_test_forward)

# Evaluar el modelo con RÂ² y MSE
r2_forward = r2_score(y_test, y_pred_forward)
mse_forward = mean_squared_error(y_test, y_pred_forward)
print("\n#### **4. Modelo con SelecciÃ³n Hacia Adelante**")
print(f"- **R cuadrada del modelo**: {r2_forward:.4f}")
print(f"- **Error CuadrÃ¡tico Medio (MSE)**: {mse_forward:.4f}")

# ======= SELECCIÃ“N HACIA ATRÃS =======
sfs_backward = SFS(model, k_features=(2, 5), forward=False, floating=False, scoring='r2', cv=10)
sfs_backward.fit(X_train[selected_features_forward], y_train)
selected_features_backward = list(sfs_backward.k_feature_names_)

print("\n#### **5. SelecciÃ³n Hacia AtrÃ¡s**")
print(f"- **CaracterÃ­sticas seleccionadas**: {selected_features_backward}")

# Entrenar el modelo con selecciÃ³n hacia atrÃ¡s
X_train_backward = X_train[selected_features_backward]
X_test_backward = X_test[selected_features_backward]
model.fit(X_train_backward, y_train)
y_pred_backward = model.predict(X_test_backward)

# Evaluar el modelo con RÂ² y MSE
r2_backward = r2_score(y_test, y_pred_backward)
mse_backward = mean_squared_error(y_test, y_pred_backward)
print("\n#### **6. Modelo con SelecciÃ³n Hacia AtrÃ¡s**")
print(f"- **R cuadrada del modelo**: {r2_backward:.4f}")
print(f"- **Error CuadrÃ¡tico Medio (MSE)**: {mse_backward:.4f}")

# ======= COMPARACIÃ“N DE MODELOS =======
r2_difference = r2_forward - r2_backward
r2_difference_pct = (r2_difference / r2_forward) * 100  # Diferencia en porcentaje

print("\n### **ComparaciÃ³n de Modelos**")
print(f"- **Modelo con selecciÃ³n hacia adelante**: RÂ² = {r2_forward:.4f}, MSE = {mse_forward:.4f}")
print(f"- **Modelo con selecciÃ³n hacia atrÃ¡s**: RÂ² = {r2_backward:.4f}, MSE = {mse_backward:.4f}")
print(f"- **Diferencia entre los modelos (RÂ²)**: {r2_difference:.4f}")
print(f"- **Diferencia en porcentaje (RÂ²)**: {r2_difference_pct:.2f}%")

# GrÃ¡fico de dispersiÃ³n de predicciones vs valores reales
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred_forward, label="SelecciÃ³n Adelante", color="blue", alpha=0.6)
sns.scatterplot(x=y_test, y=y_pred_backward, label="SelecciÃ³n AtrÃ¡s", color="red", alpha=0.6)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='black', linestyle='--')  # LÃ­nea perfecta
plt.xlabel("Calidad Real")
plt.ylabel("PredicciÃ³n del Modelo")
plt.title("ComparaciÃ³n de Predicciones vs. Valores Reales")
plt.legend()
plt.savefig("comparacion_modelos.png")
plt.show()

# ======= CONCLUSIÃ“N =======
print("\n### **ConclusiÃ³n sobre los Modelos**")
if r2_forward > r2_backward:
    print("- âœ… El modelo con selecciÃ³n hacia adelante es superior en precisiÃ³n.")
else:
    print("- ğŸ”µ El modelo con selecciÃ³n hacia atrÃ¡s es mejor en precisiÃ³n.")

print("\n### **OpiniÃ³n Final**")
print("- Ambos modelos tienen un RÂ² relativamente bajo (<0.5), lo que indica que la calidad del vino puede depender de mÃ¡s factores no considerados.")
print("- Se podrÃ­an probar modelos mÃ¡s avanzados como Ã¡rboles de decisiÃ³n, random forests o redes neuronales.")
print("- TambiÃ©n se puede mejorar el rendimiento con tÃ©cnicas de regularizaciÃ³n como Ridge o Lasso.")